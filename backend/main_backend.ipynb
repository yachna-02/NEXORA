!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn nltk openai-whisper google-cloud-language boto3 streamlit
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import torch
import nltk
import whisper
import boto3
import json

from nltk.corpus import stopwords
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from imblearn.over_sampling import RandomOverSampler
from statistics import mode
from google.cloud import language_v1

nltk.download('stopwords')

import pandas as pd
import json

def load_and_merge_data():
    # Load your base CSV dataset
    base_data = pd.read_csv("improved_disease_dataset.csv")
    base_data.columns = base_data.columns.str.lower()  # Normalize column names

    # Load FAERS JSON
    with open("faers_sample.json", "r") as f:
        faers_json = json.load(f)

    # Parse each report and extract symptoms
    faers_rows = []
    for entry in faers_json.get("results", []):  # 'results' is the correct key
        patient = entry.get("patient", {})
        reactions = patient.get("reaction", [])
        symptoms = [r.get("reactionmeddrapt", "").strip().lower() for r in reactions if r.get("reactionmeddrapt")]

        if symptoms:
            faers_rows.append({
                "symptoms": symptoms,
                "disease": "adverse_event"  # You can refine this mapping if you want
            })

    # Convert FAERS data to DataFrame
    faers_df = pd.DataFrame(faers_rows)

    # Build binary symptom columns
    all_symptoms = sorted({symptom for s_list in faers_df["symptoms"] for symptom in s_list})
    binary_symptom_df = pd.DataFrame(0, index=faers_df.index, columns=all_symptoms)
    for idx, symptoms in faers_df["symptoms"].items():
        for s in symptoms:
            binary_symptom_df.at[idx, s] = 1

    faers_data_final = pd.concat([binary_symptom_df, faers_df["disease"]], axis=1)

    # Align FAERS columns with base_data (add any missing symptom columns)
    for col in faers_data_final.columns:
        if col != "disease" and col not in base_data.columns:
            base_data[col] = 0

    faers_data_final = faers_data_final.reindex(columns=base_data.columns, fill_value=0)
    combined = pd.concat([base_data, faers_data_final], ignore_index=True).fillna(0)
    return combined



data = load_and_merge_data()
encoder = LabelEncoder()
data["disease"] = encoder.fit_transform(data["disease"])

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

if 'gender' in X_resampled.columns:
    le = LabelEncoder()
    X_resampled['gender'] = le.fit_transform(X_resampled['gender'])

X_resampled = X_resampled.fillna(0)
y_resampled = np.ravel(y_resampled)

models = {
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
}

stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for model_name, model in models.items():
    scores = cross_val_score(model, X_resampled, y_resampled, cv=stratified_kfold, scoring='accuracy')
    print("=" * 50)
    print(f"Model: {model_name}")
    print(f"Scores: {scores}")
    print(f"Mean Accuracy: {scores.mean():.4f}")

# Train individual models
svm_model = SVC()
svm_model.fit(X_resampled, y_resampled)
nb_model = GaussianNB()
nb_model.fit(X_resampled, y_resampled)
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_resampled, y_resampled)

# Evaluate combined model
svm_preds = svm_model.predict(X_resampled)
nb_preds = nb_model.predict(X_resampled)
rf_preds = rf_model.predict(X_resampled)
final_preds = [mode([i, j, k]) for i, j, k in zip(svm_preds, nb_preds, rf_preds)]
cf_matrix_combined = confusion_matrix(y_resampled, final_preds)

plt.figure(figsize=(12, 8))
sns.heatmap(cf_matrix_combined, annot=True, fmt="d")
plt.title("Confusion Matrix for Combined Model")
plt.show()
print(f"Combined Model Accuracy: {accuracy_score(y_resampled, final_preds) * 100:.2f}%")

# Prepare symptom index
symptoms = X.columns.values
symptom_index = {symptom: idx for idx, symptom in enumerate(symptoms)}

# Load Whisper model
whisper_model = whisper.load_model("medium")

# Google NLP API client
language_client = language_v1.LanguageServiceClient()

def transcribe_audio(audio_path):
    print("[INFO] Transcribing with Whisper...")
    result = whisper_model.transcribe(audio_path)
    transcription = result["text"]
    print("[TRANSCRIBED TEXT]:", transcription)
    return transcription

def extract_symptoms_google_nlp(text):
    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)
    response = language_client.analyze_entities(request={"document": document})
    entities = [entity.name.lower() for entity in response.entities]

    known_symptoms = {
        "fever", "cough", "cold", "headache", "fatigue", "sore throat",
        "shortness of breath", "nausea", "vomiting", "diarrhea", "chest pain",
        "dizziness", "runny nose", "rash", "body ache", "congestion"
    }
    return list(set(entities).intersection(known_symptoms))

def predict_disease(input_symptoms):
    input_data = [0] * len(symptom_index)
    for symptom in input_symptoms:
        if symptom in symptom_index:
            input_data[symptom_index[symptom]] = 1
    input_data = np.array(input_data).reshape(1, -1)

    rf_pred = encoder.classes_[rf_model.predict(input_data)[0]]
    nb_pred = encoder.classes_[nb_model.predict(input_data)[0]]
    svm_pred = encoder.classes_[svm_model.predict(input_data)[0]]
    final_pred = mode([rf_pred, nb_pred, svm_pred])

    return {
        "Random Forest Prediction": rf_pred,
        "Naive Bayes Prediction": nb_pred,
        "SVM Prediction": svm_pred,
        "Final Prediction": final_pred
    }

def process_audio_and_predict(audio_path):
    transcribed_text = transcribe_audio(audio_path)
    symptoms_extracted = extract_symptoms_google_nlp(transcribed_text)

    if not symptoms_extracted:
        print("No clear symptoms found.")
        return None

    result = predict_disease(symptoms_extracted)
    print("[SYMPTOMS]:", symptoms_extracted)
    print("[PREDICTION]:", result)
    return result

# Example Usage
if __name__ == "__main__":
    audio_file_path = "sample_call.mp3"  # Replace with your test audio
    process_audio_and_predict(audio_file_path)
